{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rll/deepul/blob/master/homeworks/hw1/hw1_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rdy1FtrRpGcC"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "## Overview\n",
    "This semester, all homeworks will be conducted through Google Colab notebooks. All code for the homework assignment will be written and run in this notebook. Running in Colab will automatically provide a GPU, but you may also run this notebook locally by following [these instructions](https://research.google.com/colaboratory/local-runtimes.html) if you wish to use your own GPU.\n",
    "\n",
    "You will save images in the notebooks to use and fill out a given LaTeX template which will be submitted to Gradescope, along with your notebook code.\n",
    "\n",
    "## Using Colab\n",
    "On the left-hand side, you can click the different icons to see a Table of Contents of the assignment, as well as local files accessible through the notebook.\n",
    "\n",
    "Make sure to go to **Runtime -> Change runtime type** and select **GPU** as the hardware accelerator. This allows you to use a GPU. Run the cells below to get started on the assignment. Note that a session is open for a maximum of 12 hours, and using too much GPU compute may result in restricted access for a short period of time. Please start the homework early so you have ample time to work.\n",
    "\n",
    "**If you loaded this notebook from clicking \"Open in Colab\" from github, you will need to save it to your own Google Drive to keep your work.**\n",
    "\n",
    "## General Tips\n",
    "In each homework problem, you will implement an autoregressive model and run it on two datasets (dataset 1 and dataset 2). The expected outputs for dataset 1 are already provided to help as a sanity check.\n",
    "\n",
    "Feel free to print whatever output (e.g. debugging code, training code, etc) you want, as the graded submission will be the submitted pdf with images.\n",
    "\n",
    "After you complete the assignment, download all of the image outputted in the results/ folder and upload them to the figure folder in the given latex template.\n",
    "\n",
    "Run the cells below to download and load up the starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/magda/Github/deepul/homeworks/hw1', '/home/magda/anaconda3/envs/pytorch/lib/python38.zip', '/home/magda/anaconda3/envs/pytorch/lib/python3.8', '/home/magda/anaconda3/envs/pytorch/lib/python3.8/lib-dynload', '', '/home/magda/anaconda3/envs/pytorch/lib/python3.8/site-packages', '/home/magda/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/extensions', '/home/magda/.ipython', '/home/magda/Github/deepul/homeworks', '/home/magda/Github/deepul']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !if [ -d deepul ]; then rm -Rf deepul; fi\n",
    "    !git clone -b magda https://github.com/mgswiss15/deepul.git \n",
    "    !unzip -qq deepul/homeworks/hw1/data/hw1_data.zip -d deepul/homeworks/hw1/data/\n",
    "    !pip install ./deepul\n",
    "else:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    import sys\n",
    "    import pathlib\n",
    "    cwd = pathlib.Path().absolute()\n",
    "    sys.path.append(str(cwd.parents[0]))\n",
    "    sys.path.append(str(cwd.parents[1]))\n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP8lmmk7Xrct"
   },
   "source": [
    "# Question 3 PixelCNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wnyhDNqcAcw"
   },
   "source": [
    "Now, you will train more powerful PixleCNN models on the shapes dataset and MNIST. In addition, we will extend to modelling colored datasets with and without channel conditioning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50WsEzhx4Uua"
   },
   "source": [
    "## Part (a) PixelCNN on Shapes and MNIST\n",
    "In this part, implement a simple PixelCNN architecture to model binary MNIST and shapes images (same as Q2(b), but with a PixelCNN).\n",
    "\n",
    "We recommend the following network design:\n",
    "* A $7 \\times 7$ masked type A convolution\n",
    "* $5$ $7 \\times 7$ masked type B convolutions\n",
    "* $2$ $1 \\times 1$ masked type B convolutions\n",
    "* Appropriate ReLU nonlinearities in-between\n",
    "* 64 convolutional filters\n",
    "\n",
    "And the following hyperparameters:\n",
    "* Batch size 128\n",
    "* Learning rate $10^{-3}$\n",
    "* 10 epochs\n",
    "* Adam Optimizer (this applies to all PixelCNN models trained in future parts)\n",
    "\n",
    "Your model should output logits, after which you could apply a sigmoid over 1 logit, or a softmax over two logits (either is fine). It may also help to scale your input to $[-1, 1]$ before running it through the network. \n",
    "\n",
    "Training on the shapes dataset should be quick, and MNIST should take around 10 minutes\n",
    "\n",
    "**You will provide these deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the average negative log-likelihood (nats / dim) of the training data (per minibatch) and test data (for your entire test set). Code is provided that automatically plots the training curves. \n",
    "2.   Report the final test set performance of your final model\n",
    "3. 100 samples from the final trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EleefdNuciyc"
   },
   "source": [
    "### Solution\n",
    "Fill out the function below and return the necessary arguments. Feel free to create more cells if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from deepul.exp_utils import *\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(MaskedConv2d, self).__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n",
    "        self.mask = nn.Parameter(torch.zeros(out_channels, in_channels, *self.kernel_size), requires_grad=False)\n",
    "        k_size = self.kernel_size[0]\n",
    "        kernel_mid = k_size // 2\n",
    "        if kernel_mid==0:\n",
    "            self.mask[:] = 1.\n",
    "        else:\n",
    "            for i in range(k_size):\n",
    "                for j in range(k_size):\n",
    "                    if i < kernel_mid:\n",
    "                        self.mask[:, :, i, j] = 1.\n",
    "                    elif (i == kernel_mid) & (j < kernel_mid):\n",
    "                        self.mask[:, :, i, j] = 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._conv_forward(x, self.weight * self.mask)   \n",
    "    \n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, image_shape, filters=64):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.image_shape = image_shape\n",
    "        layers = []\n",
    "        layers.append(MaskedConv2d(1, 64, 7, stride=1, padding=3))\n",
    "        for i in range(5):\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(MaskedConv2d(64, 64, 7, stride=1, padding=3))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(MaskedConv2d(64, 64, 1, stride=1, padding=0))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(MaskedConv2d(64, 1, 1, stride=1, padding=0))\n",
    "        self.sequential = nn.Sequential(*layers)\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.sequential(x.float())\n",
    "        return logits\n",
    "        \n",
    "    def loss_function(self, preds, target):\n",
    "        loss = self.loss_func(preds, target.float())\n",
    "        loss = torch.sum(loss, (3, 2, 1))\n",
    "        loss = loss.mean(dim=0)\n",
    "        return loss\n",
    "    \n",
    "    def sampling(self, size):\n",
    "        start_time = time.time()\n",
    "        print(f'Begin sampling')\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            sample = torch.ones(size, 1, *self.image_shape)\n",
    "            if next(self.parameters()).is_cuda:\n",
    "                sample = sample.cuda()\n",
    "            for i in range(self.image_shape[0]):\n",
    "                for j in range(self.image_shape[1]):\n",
    "                    logits = self(sample)\n",
    "                    sample[:, :, i, j] = torch.bernoulli(torch.sigmoid(logits[:, :, i, j]))\n",
    "                print(f'Sampled row {i}')\n",
    "            images = sample.permute(0, 2, 3, 1)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f'End sampling, elapsed {elapsed}')\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWualafa-tpD"
   },
   "outputs": [],
   "source": [
    "def q3_a(train_data, test_data, image_shape, dset_id):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    test_data: A (n_test, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    image_shape: (H, W), height and width of the image\n",
    "    dset_id: An identifying number of which dataset is given (1 or 2). Most likely\n",
    "           used to set different hyperparameters for different datasets\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - a numpy array of size (100, H, W, 1) of samples with values in {0, 1}\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    train_data = np.transpose(train_data, (0, 3, 1, 2))\n",
    "    test_data = np.transpose(test_data, (0, 3, 1, 2))   \n",
    "\n",
    "    DEVICE = torch.device('cuda')\n",
    "    train_loader, test_loader = get_loaders(train_data, test_data, bs=128)\n",
    "    model = PixelCNN((image_shape)).to(DEVICE)\n",
    "    optim_algo = torch.optim.Adam\n",
    "    nll_train, nll_test = training(\n",
    "        train_loader, test_loader,\n",
    "        model, optim_algo, learn_rate=0.001, device=DEVICE, epochs=10)\n",
    "    npixels = np.prod(np.array(image_shape))\n",
    "    nll_train = np.array(nll_train) / npixels\n",
    "    nll_test = np.array(nll_test) / npixels\n",
    "    return nll_train, nll_test, model.sampling(100).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0EPVfz1cpq0"
   },
   "source": [
    "### Results\n",
    "\n",
    "Once you've implemented `q3_a`, execute the cells below to visualize and save your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "xNxXqVZpAd_V",
    "outputId": "9280e0c4-d8de-408d-e0d6-af0ffa777527"
   },
   "outputs": [],
   "source": [
    "q3a_save_results(1, q3_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3a_save_results(2, q3_a)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Homework 1 Autoregressive Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "5"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
