{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/magda/Github/deepul/homeworks/hw2', '/home/magda/anaconda3/envs/pytorch/lib/python38.zip', '/home/magda/anaconda3/envs/pytorch/lib/python3.8', '/home/magda/anaconda3/envs/pytorch/lib/python3.8/lib-dynload', '', '/home/magda/anaconda3/envs/pytorch/lib/python3.8/site-packages', '/home/magda/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/extensions', '/home/magda/.ipython', '/home/magda/Github/deepul/homeworks', '/home/magda/Github/deepul']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !if [ -d deepul ]; then rm -Rf deepul; fi\n",
    "    !git clone -b magda https://github.com/mgswiss15/deepul.git \n",
    "    !unzip -qq deepul/homeworks/hw1/data/hw1_data.zip -d deepul/homeworks/hw1/data/\n",
    "    !pip install ./deepul\n",
    "else:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    import sys\n",
    "    import pathlib\n",
    "    cwd = pathlib.Path().absolute()\n",
    "    sys.path.append(str(cwd.parents[0]))\n",
    "    sys.path.append(str(cwd.parents[1]))\n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepul.notebook2script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def training(train_loader, test_loader, model, optim_algo, learn_rate, device=torch.device('cpu'), epochs=20, grad_clip=None, warmup=200):\n",
    "    nll_train = []\n",
    "    nll_test = []\n",
    "    optimizer = optim_algo(model.parameters(), learn_rate)\n",
    "    print('First eval')\n",
    "    test_loss = evaluate(test_loader, model, device)\n",
    "    nll_test.append(test_loss)\n",
    "    print('Training loop')\n",
    "    for epoch in range(epochs):\n",
    "        loss_list = train(train_loader, model, optimizer, learn_rate, device, grad_clip=grad_clip, warmup=warmup)\n",
    "        nll_train += loss_list\n",
    "        test_loss = evaluate(test_loader, model, device)\n",
    "        nll_test.append(test_loss)\n",
    "        if epoch%10. == 0.:\n",
    "            print(f'Epoch {epoch} loss train: {loss_list[-1]}, test: {nll_test[-1]}')\n",
    "    return nll_train, nll_test\n",
    "        \n",
    "def train(train_loader, model, optimizer, learn_rate, device, grad_clip=None, warmup=200):\n",
    "    \"\"\"For back compatibility batch can be (input) or (input, output)\"\"\"\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        lr = min(1, 1/warmup * i) * learn_rate\n",
    "        optimizer.lr = lr\n",
    "        if isinstance(batch, list):\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = [x, y]\n",
    "        else:\n",
    "            batch = batch.to(device).requires_grad_()\n",
    "        latent, log_det_jacobian = model(batch)\n",
    "        loss = model.loss_function(latent, log_det_jacobian) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if grad_clip:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "    return loss_list\n",
    "\n",
    "def evaluate(test_loader, model, device):\n",
    "    '''Evaluate without no_grad'''\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for batch in test_loader:\n",
    "            if isinstance(batch, list):\n",
    "                x, y = batch\n",
    "                n_inst = x.shape[0]\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                batch = [x, y]\n",
    "            else:\n",
    "                n_inst = batch.shape[0]\n",
    "                batch = batch.to(device)\n",
    "            latent, log_det_jacobian = model(batch)\n",
    "            loss += model.loss_function(latent, log_det_jacobian).item() * n_inst\n",
    "    total_loss = loss / len(test_loader.dataset)\n",
    "    return total_loss\n",
    "        \n",
    "def get_loaders(train_data, test_data, bs):\n",
    "    \"\"\"For back compatibility works with datasets and numpy arrays as inputs\"\"\"\n",
    "    if isinstance(train_data, np.ndarray):\n",
    "        train_data = torch.as_tensor(train_data, dtype=torch.float)\n",
    "        test_data = torch.as_tensor(test_data, dtype=torch.float)\n",
    "    assert (isinstance(train_data, data.Dataset) | isinstance(train_data, torch.Tensor)), print(f'train_data are not in good format (np.ndarray, torch.Tensor or data.Dataset)')\n",
    "    train_loader = data.DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "    test_loader = data.DataLoader(test_data, batch_size=bs, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Utils2.ipynb to /home/magda/Github/deepul/deepul/exp_utils2.py\n"
     ]
    }
   ],
   "source": [
    "nb2script('Utils2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "5"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
