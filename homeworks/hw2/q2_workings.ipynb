{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigmoidLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = torch.sigmoid(x)\n",
    "        det = z * (1 - z)\n",
    "        return z, det\n",
    "    \n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, image_shape, n_layers=3, n_hidden=64, n_couplings=5, device='cuda', base_distrib='Normal'):\n",
    "        super(RealNVP, self).__init__()\n",
    "        self.image_shape = image_shape\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_couplings = n_couplings\n",
    "        self.base_distrib = base_distrib\n",
    "        self.layers = nn.ModuleList()\n",
    "        n_in = image_shape[0]\n",
    "        start_from = 1\n",
    "        for _ in range(4):\n",
    "            self.layers.append(AffineCouplingChecker(start_from, n_in, n_out, n_filters, n_blocks):\n",
    "            )\n",
    "        [\n",
    "            CouplingLayer(self.n_layers, self.n_hidden) for _ in range(n_couplings)\n",
    "        ])\n",
    "        if self.base_distrib=='Normal':\n",
    "            self.base = Normal(torch.tensor([0., 0.], device=device), torch.tensor([1., 1.], device=device))\n",
    "        elif self.base_distrib=='Uniform':\n",
    "            self.base = Uniform(torch.tensor([0., 0.], device=device), torch.tensor([1., 1.], device=device))\n",
    "            self.sigmoid = SigmoidLayer()\n",
    "        else:\n",
    "            raise NotImplementedError('Sorry, base distribution can only be Uniform or Normal')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dets = torch.ones_like(x[:,0:1])\n",
    "        indata = x\n",
    "        for layer in self.layers:\n",
    "            z, d = layer(indata)\n",
    "            indata = z\n",
    "            dets = torch.cat((dets, d), dim=1)\n",
    "        if self.base_distrib == 'Uniform':\n",
    "            z, d = self.sigmoid(z)\n",
    "            dets = torch.cat((dets, d), dim=1)\n",
    "        return z, dets\n",
    "            \n",
    "    def log_prob_x_from_z(self, z, dets):\n",
    "        if self.base_distrib == 'Uniform':\n",
    "            log_prob = dets.abs().log().sum(dim=1)  # use independent uniform - this breaks\n",
    "        else:\n",
    "            log_prob = self.base.log_prob(z).sum(dim=1) + dets.abs().log().sum(dim=1)  # can sum log_probs cause independent\n",
    "        return log_prob\n",
    "    \n",
    "    def loss_function(self, z, dets):\n",
    "        loss = -self.log_prob_x_from_z(z, dets).mean()\n",
    "        return loss\n",
    "    \n",
    "    def eval_log_prob(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z, dets = self(x)\n",
    "            log_prob = self.log_prob_x_from_z(z, dets)\n",
    "        return log_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "5"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
